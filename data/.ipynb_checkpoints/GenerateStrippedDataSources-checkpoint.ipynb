{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modifications\n",
    "This notebook will strip out the uneeeded fields from the source data files in order to cut down on the amount of data placed into the databases and import times for files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\luke\\anaconda3\\lib\\site-packages (4.47.0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_chunks(data, chunk_size):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i: i+chunk_size]\n",
    "\n",
    "def generate_stripped_file(file_name, remove_fields):\n",
    "    #Open the data file\n",
    "    with open (file_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    #Remove the data for each field in the remove_fields list\n",
    "    for row in tqdm(data, desc=\"Removing Uneeded Fields...\"):\n",
    "        for field in remove_fields:\n",
    "            row.pop(field, None)\n",
    "    \n",
    "    #Append _stripped.json to the file name to create the new file\n",
    "    stripped_file_name = file_name[:-5] + '_stripped.json'\n",
    "    #Write the new contents to the new data file\n",
    "    with open (stripped_file_name, 'w') as stripped_file:\n",
    "        json.dump(data, stripped_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commodities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'commodities.json'\n",
    "remove_fields = ['is_rare', 'is_non_marketable']\n",
    "generate_stripped_file(file_name, remove_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'factions.json'\n",
    "remove_fields = ['updated_at', 'is_player_faction', 'government_id', 'alliance_id']\n",
    "generate_stripped_file(file_name, remove_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'modules.json'\n",
    "remove_fields = ['belongs_to', 'ed_id', 'game_context_id']\n",
    "generate_stripped_file(file_name, remove_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Uneeded Fields...: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 66024/66024 [00:00<00:00, 421654.78it/s]\n",
      "Writing module chunk files...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 113/113 [00:09<00:00, 12.41it/s]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'stations.json'\n",
    "remove_fields = ['updated_at', 'government_id', 'alliance_id', 'shipyard_updated_at', 'outfitting_updated_at', \n",
    "                 'market_updated_at', 'ed_market_id', 'body_id']\n",
    "generate_stripped_file(file_name, remove_fields)\n",
    "\n",
    "with open ('stations.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "#Generate the modules listings .csv files from the stations\n",
    "data_list = []\n",
    "for row in data:\n",
    "    if row['selling_modules']:\n",
    "        data_list.append({'station_id': row['id'], 'modules': row['selling_modules']})\n",
    "chunks = list(generate_chunks(data_list, 400))\n",
    "csv_columns = data_list[0].keys()\n",
    "for i in tqdm(range(len(chunks)), desc=\"Writing module chunk files...\"):\n",
    "    with open (f'module_listings/modules_listing{i}.csv', 'w', newline='') as module_file:\n",
    "        writer = csv.DictWriter(module_file, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for row in chunks[i]:\n",
    "            writer.writerow(row)\n",
    "del chunks\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'systems_populated.json'\n",
    "remove_fields = ['allegiance_id', 'security_id', 'primary_economy_id', 'power_state_id', 'reserve_type_id', \n",
    "                 'ed_system_address']\n",
    "generate_stripped_file(file_name, remove_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Uneeded Fields...: 100%|████████████████████████████████████████| 3931637/3931637 [00:04<00:00, 882091.26it/s]\n",
      "Writing Chunk Files...: 100%|██████████████████████████████████████████████████████████| 16/16 [00:19<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "remove_fields = ['supply_bracket', 'demand_bracket', 'collected_at']\n",
    "\n",
    "with open ('listings.csv', 'r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    data = list(csv_reader)\n",
    "    \n",
    "for row in tqdm(data, desc=\"Removing Uneeded Fields...\"):\n",
    "    for field in remove_fields:\n",
    "        row.pop(field, None)\n",
    "\n",
    "chunks = list(generate_chunks(data, int(len(data)/15)))\n",
    "csv_columns = data[0].keys()\n",
    "for i in tqdm(range(len(chunks)), desc=\"Writing Chunk Files...\"):\n",
    "    with open (f'listing_chunks/listings_stripped{i}.csv', 'w', newline='') as stripped_file:\n",
    "        writer = csv.DictWriter(stripped_file, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for row in chunks[i]:\n",
    "            writer.writerow(row)\n",
    "del data\n",
    "del chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
