{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modifications\n",
    "This notebook will strip out the uneeeded fields from the source data files in order to cut down on the amount of data placed into the databases and import times for files.\n",
    "\n",
    "**Note: You must create the modules_listings and listing_chunks directories in the data folder if they do not already exist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_chunks(data, chunk_size):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i: i+chunk_size]\n",
    "\n",
    "def generate_stripped_file(file_name, remove_fields, add_fields = []):\n",
    "    #Open the data file\n",
    "    with open (file_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    #Remove the data for each field in the remove_fields list\n",
    "    for row in tqdm(data, desc=\"Removing Uneeded Fields...\"):\n",
    "        for field in remove_fields:\n",
    "            row.pop(field, None)\n",
    "        for field in add_fields:\n",
    "            row[field['name']] = field['func'](row)\n",
    "    \n",
    "    #Append _stripped.json to the file name to create the new file\n",
    "    stripped_file_name = file_name[:-5] + '_stripped.json'\n",
    "    #Write the new contents to the new data file\n",
    "    with open (stripped_file_name, 'w') as stripped_file:\n",
    "        json.dump(data, stripped_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commodities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'commodities.json'\n",
    "remove_fields = ['is_rare', 'is_non_marketable']\n",
    "generate_stripped_file(file_name, remove_fields)\n",
    "\n",
    "commodity_map = {}\n",
    "with open ('commodities_stripped.json', 'r') as file:\n",
    "    commodity_data = json.load(file)\n",
    "    for row in commodity_data:\n",
    "        commodity_map[row['id']] = row['name']\n",
    "#Remove this variable so it \n",
    "del commodity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'factions.json'\n",
    "remove_fields = ['updated_at', 'is_player_faction', 'government_id', 'allegiance_id']\n",
    "generate_stripped_file(file_name, remove_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'modules.json'\n",
    "remove_fields = ['belongs_to', 'ed_id', 'game_context_id']\n",
    "generate_stripped_file(file_name, remove_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'systems_populated.json'\n",
    "remove_fields = ['government_id', 'allegiance_id', 'security_id', 'primary_economy_id', 'power_state_id', 'reserve_type_id', \n",
    "                 'ed_system_address']\n",
    "generate_stripped_file(file_name, remove_fields)\n",
    "\n",
    "system_map = {}\n",
    "with open('systems_populated_stripped.json', 'r') as file:\n",
    "    system_data = json.load(file)\n",
    "    for row in system_data:\n",
    "        system_map[row['id']] = row['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_name(row):\n",
    "    if row['system_id'] in system_map:\n",
    "        return system_map[row['system_id']]\n",
    "    return None\n",
    "\n",
    "file_name = 'stations.json'\n",
    "remove_fields = ['updated_at', 'government_id', 'allegience_id', 'shipyard_updated_at', 'outfitting_updated_at', \n",
    "                 'market_updated_at', 'ed_market_id', 'body_id']\n",
    "add_fields = [{'name': 'system_name', 'func': get_system_name}]\n",
    "generate_stripped_file(file_name, remove_fields, add_fields)\n",
    "\n",
    "with open ('stations.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "#Generate the modules listings .csv files from the stations\n",
    "data_list = []\n",
    "for row in data:\n",
    "    if row['selling_modules']:\n",
    "        data_list.append({'station_id': row['id'], 'modules': row['selling_modules']})\n",
    "chunks = list(generate_chunks(data_list, 400))\n",
    "csv_columns = data_list[0].keys()\n",
    "for i in tqdm(range(len(chunks)), desc=\"Writing module chunk files...\"):\n",
    "    with open (f'module_listings/modules_listing{i}.csv', 'w', newline='') as module_file:\n",
    "        writer = csv.DictWriter(module_file, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for row in chunks[i]:\n",
    "            writer.writerow(row)\n",
    "del chunks\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commodity_name(row):\n",
    "    return commodity_map[int(row['commodity_id'])]\n",
    "\n",
    "remove_fields = ['supply_bracket', 'demand_bracket', 'collected_at']\n",
    "add_fields = [{'name': 'commodity_name', 'func': get_commodity_name}]\n",
    "\n",
    "with open ('listings.csv', 'r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    data = list(csv_reader)\n",
    "    \n",
    "for row in tqdm(data, desc=\"Removing Uneeded Fields...\"):\n",
    "    for field in remove_fields:\n",
    "        row.pop(field, None)\n",
    "    for field in add_fields:\n",
    "        row[field['name']] = field['func'](row)\n",
    "\n",
    "csv_columns = data[0].keys()\n",
    "with open (f'listings_stripped.csv', 'w', newline='') as stripped_file:\n",
    "    writer = csv.DictWriter(stripped_file, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "chunks = list(generate_chunks(data, int(len(data)/15)))\n",
    "for i in tqdm(range(len(chunks)), desc=\"Writing Chunk Files...\"):\n",
    "    with open (f'listing_chunks/listings_stripped{i}.csv', 'w', newline='') as stripped_file:\n",
    "        writer = csv.DictWriter(stripped_file, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for row in chunks[i]:\n",
    "            writer.writerow(row)\n",
    "del data\n",
    "del chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
