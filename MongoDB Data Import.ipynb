{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (4.47.0)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To establish connection:\n",
    "db = MongoClient('localhost', 27017)['EDDB']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import all of the files\n",
    "\n",
    "# files = ['commodities', 'factions', 'modules', 'stations', 'systems_populated']\n",
    "\n",
    "# for x in files:\n",
    "#     print(x)\n",
    "#     with open(f\"{x}.json\") as f:\n",
    "#         db[x].insert_many(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a CSV to JSON\n",
    "def make_json(data, csvFilePath): \n",
    "      \n",
    "    # Open a csv reader called DictReader \n",
    "    with open(csvFilePath, encoding='utf-8') as csvf: \n",
    "        csvReader = csv.DictReader(csvf) \n",
    "          \n",
    "        # Convert each row into a dictionary  \n",
    "        # and add it to data \n",
    "        for rows in tqdm(csvReader, desc=\"Reading file\"): \n",
    "              \n",
    "            # Assuming a column named 'No' to \n",
    "            # be the primary key \n",
    "            key = rows['id'] \n",
    "            data[key] = rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building system id set: 100%|██████████| 20569/20569 [00:00<00:00, 1371409.66it/s]\n",
      "Building station id set: 100%|██████████| 66024/66024 [00:00<00:00, 1100379.19it/s]\n",
      "Reading file: 3931637it [00:13, 293077.69it/s]\n",
      "Converting data to correct list of JSON...: 100%|██████████| 3931637/3931637 [00:02<00:00, 1743518.54it/s]\n",
      "Converting strings to ints...: 100%|██████████| 3931637/3931637 [00:16<00:00, 234640.58it/s]\n",
      "Filtering out listings from systems we don't have: 100%|██████████| 3931637/3931637 [00:02<00:00, 1954096.17it/s]\n",
      "Chunking...: 100%|██████████| 3932/3932 [00:00<00:00, 5966.62it/s]\n",
      "Uploading Chunks: 100%|██████████| 3932/3932 [01:24<00:00, 46.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# import listing data that is in csv file\n",
    "station_data = []\n",
    "\n",
    "with open(\"stations.json\") as f:\n",
    "        station_data = json.load(f)\n",
    "\n",
    "station_ids = set()\n",
    "\n",
    "system_data = []\n",
    "\n",
    "with open(\"systems_populated.json\") as f:\n",
    "        system_data = json.load(f)\n",
    "\n",
    "system_ids = set()\n",
    "    \n",
    "for dic in tqdm(system_data, desc=\"Building system id set\"):\n",
    "    system_ids.add(dic['id'])\n",
    "    \n",
    "for dic in tqdm(station_data, desc=\"Building station id set\"):\n",
    "    if(dic['system_id'] in system_ids):\n",
    "        station_ids.add(dic['id'])\n",
    "    \n",
    "chunk_size = 1000\n",
    "\n",
    "data_dict = {}\n",
    "make_json(data_dict, 'listings.csv')\n",
    "\n",
    "\n",
    "data_to_insert = []\n",
    "for key in tqdm(data_dict, desc=\"Converting data to correct list of JSON...\"):\n",
    "    data_to_insert.append(data_dict[key])\n",
    "\n",
    "for dic in tqdm(data_to_insert, desc=\"Converting strings to ints...\"):\n",
    "    for key in dic:\n",
    "        if(dic[key] == ''):\n",
    "            dic[key] = 0\n",
    "        else:\n",
    "            dic[key] = int(dic[key])\n",
    "\n",
    "filtered_data = []\n",
    "\n",
    "for dic in tqdm(data_to_insert, desc=\"Filtering out listings from systems we don't have\"):\n",
    "    if(dic['station_id'] in station_ids):\n",
    "        filtered_data.append(dic)\n",
    "            \n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in tqdm(range(0, len(lst), n), desc=\"Chunking...\"):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "chunks = list(chunks(filtered_data, chunk_size))\n",
    "        \n",
    "for chunk in tqdm(chunks, desc=\"Uploading Chunks\"):\n",
    "    db['listings'].insert_many(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
